{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Parkinson's Disease\n",
    "This notebook uses the dataset from [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification) and classification models to predict whether a patient has Parkinson's Disease, with a focus on Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/byron/Documents/GitHub/project-parkinsons-disease-classification/data/pd_speech_features.csv', \n",
    "                 header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(756, 755)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tqwt_kurtosisValue_dec_28</th>\n",
       "      <th>tqwt_kurtosisValue_dec_29</th>\n",
       "      <th>tqwt_kurtosisValue_dec_30</th>\n",
       "      <th>tqwt_kurtosisValue_dec_31</th>\n",
       "      <th>tqwt_kurtosisValue_dec_32</th>\n",
       "      <th>tqwt_kurtosisValue_dec_33</th>\n",
       "      <th>tqwt_kurtosisValue_dec_34</th>\n",
       "      <th>tqwt_kurtosisValue_dec_35</th>\n",
       "      <th>tqwt_kurtosisValue_dec_36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85247</td>\n",
       "      <td>0.71826</td>\n",
       "      <td>0.57227</td>\n",
       "      <td>240</td>\n",
       "      <td>239</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.00218</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5620</td>\n",
       "      <td>2.6445</td>\n",
       "      <td>3.8686</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>5.1221</td>\n",
       "      <td>4.4625</td>\n",
       "      <td>2.6202</td>\n",
       "      <td>3.0004</td>\n",
       "      <td>18.9405</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76686</td>\n",
       "      <td>0.69481</td>\n",
       "      <td>0.53966</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5589</td>\n",
       "      <td>3.6107</td>\n",
       "      <td>23.5155</td>\n",
       "      <td>14.1962</td>\n",
       "      <td>11.0261</td>\n",
       "      <td>9.5082</td>\n",
       "      <td>6.5245</td>\n",
       "      <td>6.3431</td>\n",
       "      <td>45.1780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85083</td>\n",
       "      <td>0.67604</td>\n",
       "      <td>0.58982</td>\n",
       "      <td>232</td>\n",
       "      <td>231</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.00176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5643</td>\n",
       "      <td>2.3308</td>\n",
       "      <td>9.4959</td>\n",
       "      <td>10.7458</td>\n",
       "      <td>11.0177</td>\n",
       "      <td>4.8066</td>\n",
       "      <td>2.9199</td>\n",
       "      <td>3.1495</td>\n",
       "      <td>4.7666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41121</td>\n",
       "      <td>0.79672</td>\n",
       "      <td>0.59257</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7805</td>\n",
       "      <td>3.5664</td>\n",
       "      <td>5.2558</td>\n",
       "      <td>14.0403</td>\n",
       "      <td>4.2235</td>\n",
       "      <td>4.6857</td>\n",
       "      <td>4.8460</td>\n",
       "      <td>6.2650</td>\n",
       "      <td>4.0603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32790</td>\n",
       "      <td>0.79782</td>\n",
       "      <td>0.53028</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1727</td>\n",
       "      <td>5.8416</td>\n",
       "      <td>6.0805</td>\n",
       "      <td>5.7621</td>\n",
       "      <td>7.7817</td>\n",
       "      <td>11.6891</td>\n",
       "      <td>8.2103</td>\n",
       "      <td>5.0559</td>\n",
       "      <td>6.1164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50780</td>\n",
       "      <td>0.78744</td>\n",
       "      <td>0.65451</td>\n",
       "      <td>226</td>\n",
       "      <td>221</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.00783</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8025</td>\n",
       "      <td>5.0734</td>\n",
       "      <td>7.0166</td>\n",
       "      <td>5.9966</td>\n",
       "      <td>5.2065</td>\n",
       "      <td>7.4246</td>\n",
       "      <td>3.4153</td>\n",
       "      <td>3.5046</td>\n",
       "      <td>3.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76095</td>\n",
       "      <td>0.62145</td>\n",
       "      <td>0.54543</td>\n",
       "      <td>322</td>\n",
       "      <td>321</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>...</td>\n",
       "      <td>117.2678</td>\n",
       "      <td>75.3156</td>\n",
       "      <td>32.0478</td>\n",
       "      <td>7.7060</td>\n",
       "      <td>3.1060</td>\n",
       "      <td>4.6206</td>\n",
       "      <td>12.8353</td>\n",
       "      <td>13.8300</td>\n",
       "      <td>7.7693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.83671</td>\n",
       "      <td>0.62079</td>\n",
       "      <td>0.51179</td>\n",
       "      <td>318</td>\n",
       "      <td>317</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8564</td>\n",
       "      <td>11.8909</td>\n",
       "      <td>7.2891</td>\n",
       "      <td>4.3682</td>\n",
       "      <td>3.6443</td>\n",
       "      <td>5.9610</td>\n",
       "      <td>11.7552</td>\n",
       "      <td>18.0927</td>\n",
       "      <td>5.0448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80826</td>\n",
       "      <td>0.61766</td>\n",
       "      <td>0.50447</td>\n",
       "      <td>318</td>\n",
       "      <td>317</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.00161</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2640</td>\n",
       "      <td>6.3993</td>\n",
       "      <td>4.4165</td>\n",
       "      <td>4.2662</td>\n",
       "      <td>3.6357</td>\n",
       "      <td>3.7346</td>\n",
       "      <td>2.9394</td>\n",
       "      <td>3.6216</td>\n",
       "      <td>3.8430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85302</td>\n",
       "      <td>0.62247</td>\n",
       "      <td>0.54855</td>\n",
       "      <td>493</td>\n",
       "      <td>492</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6796</td>\n",
       "      <td>2.0474</td>\n",
       "      <td>2.8117</td>\n",
       "      <td>3.5070</td>\n",
       "      <td>3.2727</td>\n",
       "      <td>3.8415</td>\n",
       "      <td>3.9439</td>\n",
       "      <td>5.8807</td>\n",
       "      <td>38.7211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 755 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  gender      PPE      DFA     RPDE  numPulses  numPeriodsPulses  \\\n",
       "0   0       1  0.85247  0.71826  0.57227        240               239   \n",
       "1   0       1  0.76686  0.69481  0.53966        234               233   \n",
       "2   0       1  0.85083  0.67604  0.58982        232               231   \n",
       "3   1       0  0.41121  0.79672  0.59257        178               177   \n",
       "4   1       0  0.32790  0.79782  0.53028        236               235   \n",
       "5   1       0  0.50780  0.78744  0.65451        226               221   \n",
       "6   2       1  0.76095  0.62145  0.54543        322               321   \n",
       "7   2       1  0.83671  0.62079  0.51179        318               317   \n",
       "8   2       1  0.80826  0.61766  0.50447        318               317   \n",
       "9   3       0  0.85302  0.62247  0.54855        493               492   \n",
       "\n",
       "   meanPeriodPulses  stdDevPeriodPulses  locPctJitter  ...    \\\n",
       "0          0.008064            0.000087       0.00218  ...     \n",
       "1          0.008258            0.000073       0.00195  ...     \n",
       "2          0.008340            0.000060       0.00176  ...     \n",
       "3          0.010858            0.000183       0.00419  ...     \n",
       "4          0.008162            0.002669       0.00535  ...     \n",
       "5          0.007631            0.002696       0.00783  ...     \n",
       "6          0.005991            0.000107       0.00222  ...     \n",
       "7          0.006074            0.000136       0.00282  ...     \n",
       "8          0.006057            0.000069       0.00161  ...     \n",
       "9          0.003910            0.000040       0.00075  ...     \n",
       "\n",
       "   tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
       "0                     1.5620                     2.6445   \n",
       "1                     1.5589                     3.6107   \n",
       "2                     1.5643                     2.3308   \n",
       "3                     3.7805                     3.5664   \n",
       "4                     6.1727                     5.8416   \n",
       "5                     4.8025                     5.0734   \n",
       "6                   117.2678                    75.3156   \n",
       "7                     3.8564                    11.8909   \n",
       "8                     2.2640                     6.3993   \n",
       "9                     1.6796                     2.0474   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
       "0                     3.8686                     4.2105   \n",
       "1                    23.5155                    14.1962   \n",
       "2                     9.4959                    10.7458   \n",
       "3                     5.2558                    14.0403   \n",
       "4                     6.0805                     5.7621   \n",
       "5                     7.0166                     5.9966   \n",
       "6                    32.0478                     7.7060   \n",
       "7                     7.2891                     4.3682   \n",
       "8                     4.4165                     4.2662   \n",
       "9                     2.8117                     3.5070   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
       "0                     5.1221                     4.4625   \n",
       "1                    11.0261                     9.5082   \n",
       "2                    11.0177                     4.8066   \n",
       "3                     4.2235                     4.6857   \n",
       "4                     7.7817                    11.6891   \n",
       "5                     5.2065                     7.4246   \n",
       "6                     3.1060                     4.6206   \n",
       "7                     3.6443                     5.9610   \n",
       "8                     3.6357                     3.7346   \n",
       "9                     3.2727                     3.8415   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
       "0                     2.6202                     3.0004   \n",
       "1                     6.5245                     6.3431   \n",
       "2                     2.9199                     3.1495   \n",
       "3                     4.8460                     6.2650   \n",
       "4                     8.2103                     5.0559   \n",
       "5                     3.4153                     3.5046   \n",
       "6                    12.8353                    13.8300   \n",
       "7                    11.7552                    18.0927   \n",
       "8                     2.9394                     3.6216   \n",
       "9                     3.9439                     5.8807   \n",
       "\n",
       "   tqwt_kurtosisValue_dec_36  class  \n",
       "0                    18.9405      1  \n",
       "1                    45.1780      1  \n",
       "2                     4.7666      1  \n",
       "3                     4.0603      1  \n",
       "4                     6.1164      1  \n",
       "5                     3.2250      1  \n",
       "6                     7.7693      1  \n",
       "7                     5.0448      1  \n",
       "8                     3.8430      1  \n",
       "9                    38.7211      1  \n",
       "\n",
       "[10 rows x 755 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of attribute datatypes:\n",
      "float64    749\n",
      "int64        6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Summary of attribute datatypes:\\n', df.dtypes.value_counts(), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of null values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of 3 records for each patient, and all the columns, except for gender, seem to be numeric. Therefore, gender will be transformed into categorical variable, and mean value of the rest attributes will be calculated by id (patient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>PPE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>numPulses</th>\n",
       "      <th>numPeriodsPulses</th>\n",
       "      <th>meanPeriodPulses</th>\n",
       "      <th>stdDevPeriodPulses</th>\n",
       "      <th>locPctJitter</th>\n",
       "      <th>locAbsJitter</th>\n",
       "      <th>...</th>\n",
       "      <th>tqwt_kurtosisValue_dec_28</th>\n",
       "      <th>tqwt_kurtosisValue_dec_29</th>\n",
       "      <th>tqwt_kurtosisValue_dec_30</th>\n",
       "      <th>tqwt_kurtosisValue_dec_31</th>\n",
       "      <th>tqwt_kurtosisValue_dec_32</th>\n",
       "      <th>tqwt_kurtosisValue_dec_33</th>\n",
       "      <th>tqwt_kurtosisValue_dec_34</th>\n",
       "      <th>tqwt_kurtosisValue_dec_35</th>\n",
       "      <th>tqwt_kurtosisValue_dec_36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.823387</td>\n",
       "      <td>0.696370</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>235.333333</td>\n",
       "      <td>234.333333</td>\n",
       "      <td>0.008220</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561733</td>\n",
       "      <td>2.862000</td>\n",
       "      <td>12.293333</td>\n",
       "      <td>9.717500</td>\n",
       "      <td>9.055300</td>\n",
       "      <td>6.259100</td>\n",
       "      <td>4.021533</td>\n",
       "      <td>4.164333</td>\n",
       "      <td>22.961700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415637</td>\n",
       "      <td>0.793993</td>\n",
       "      <td>0.592453</td>\n",
       "      <td>213.333333</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>4.918567</td>\n",
       "      <td>4.827133</td>\n",
       "      <td>6.117633</td>\n",
       "      <td>8.599667</td>\n",
       "      <td>5.737233</td>\n",
       "      <td>7.933133</td>\n",
       "      <td>5.490533</td>\n",
       "      <td>4.941833</td>\n",
       "      <td>4.467233</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.801973</td>\n",
       "      <td>0.619967</td>\n",
       "      <td>0.520563</td>\n",
       "      <td>319.333333</td>\n",
       "      <td>318.333333</td>\n",
       "      <td>0.006041</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>...</td>\n",
       "      <td>41.129400</td>\n",
       "      <td>31.201933</td>\n",
       "      <td>14.584467</td>\n",
       "      <td>5.446800</td>\n",
       "      <td>3.462000</td>\n",
       "      <td>4.772067</td>\n",
       "      <td>9.176633</td>\n",
       "      <td>11.848100</td>\n",
       "      <td>5.552367</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.828707</td>\n",
       "      <td>0.626097</td>\n",
       "      <td>0.537183</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.677633</td>\n",
       "      <td>1.908400</td>\n",
       "      <td>2.842167</td>\n",
       "      <td>3.493867</td>\n",
       "      <td>3.282433</td>\n",
       "      <td>3.085267</td>\n",
       "      <td>3.184433</td>\n",
       "      <td>4.032933</td>\n",
       "      <td>22.773633</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831287</td>\n",
       "      <td>0.779397</td>\n",
       "      <td>0.726717</td>\n",
       "      <td>362.666667</td>\n",
       "      <td>361.666667</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.003593</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>4.104600</td>\n",
       "      <td>4.285233</td>\n",
       "      <td>2.953200</td>\n",
       "      <td>2.799933</td>\n",
       "      <td>2.645100</td>\n",
       "      <td>2.811367</td>\n",
       "      <td>7.268333</td>\n",
       "      <td>13.338833</td>\n",
       "      <td>63.766900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 754 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender       PPE       DFA      RPDE   numPulses  numPeriodsPulses  \\\n",
       "id                                                                      \n",
       "0     1.0  0.823387  0.696370  0.567250  235.333333        234.333333   \n",
       "1     0.0  0.415637  0.793993  0.592453  213.333333        211.000000   \n",
       "2     1.0  0.801973  0.619967  0.520563  319.333333        318.333333   \n",
       "3     0.0  0.828707  0.626097  0.537183  493.000000        492.000000   \n",
       "4     0.0  0.831287  0.779397  0.726717  362.666667        361.666667   \n",
       "\n",
       "    meanPeriodPulses  stdDevPeriodPulses  locPctJitter  locAbsJitter  ...    \\\n",
       "id                                                                    ...     \n",
       "0           0.008220            0.000073      0.001963      0.000016  ...     \n",
       "1           0.008884            0.001849      0.005790      0.000050  ...     \n",
       "2           0.006041            0.000104      0.002217      0.000013  ...     \n",
       "3           0.003913            0.000042      0.000757      0.000003  ...     \n",
       "4           0.005622            0.002023      0.003593      0.000021  ...     \n",
       "\n",
       "    tqwt_kurtosisValue_dec_28  tqwt_kurtosisValue_dec_29  \\\n",
       "id                                                         \n",
       "0                    1.561733                   2.862000   \n",
       "1                    4.918567                   4.827133   \n",
       "2                   41.129400                  31.201933   \n",
       "3                    1.677633                   1.908400   \n",
       "4                    4.104600                   4.285233   \n",
       "\n",
       "    tqwt_kurtosisValue_dec_30  tqwt_kurtosisValue_dec_31  \\\n",
       "id                                                         \n",
       "0                   12.293333                   9.717500   \n",
       "1                    6.117633                   8.599667   \n",
       "2                   14.584467                   5.446800   \n",
       "3                    2.842167                   3.493867   \n",
       "4                    2.953200                   2.799933   \n",
       "\n",
       "    tqwt_kurtosisValue_dec_32  tqwt_kurtosisValue_dec_33  \\\n",
       "id                                                         \n",
       "0                    9.055300                   6.259100   \n",
       "1                    5.737233                   7.933133   \n",
       "2                    3.462000                   4.772067   \n",
       "3                    3.282433                   3.085267   \n",
       "4                    2.645100                   2.811367   \n",
       "\n",
       "    tqwt_kurtosisValue_dec_34  tqwt_kurtosisValue_dec_35  \\\n",
       "id                                                         \n",
       "0                    4.021533                   4.164333   \n",
       "1                    5.490533                   4.941833   \n",
       "2                    9.176633                  11.848100   \n",
       "3                    3.184433                   4.032933   \n",
       "4                    7.268333                  13.338833   \n",
       "\n",
       "    tqwt_kurtosisValue_dec_36  class  \n",
       "id                                    \n",
       "0                   22.961700    1.0  \n",
       "1                    4.467233    1.0  \n",
       "2                    5.552367    1.0  \n",
       "3                   22.773633    1.0  \n",
       "4                   63.766900    1.0  \n",
       "\n",
       "[5 rows x 754 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean = df.groupby(['id']).mean()\n",
    "df_mean.gender = df_mean.gender.astype('category')\n",
    "df_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model\n",
    "The following classification models are used to get baseline performance:\n",
    "- Logistic Regression\n",
    "- Linear SVM\n",
    "- SVM\n",
    "- kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_base = df_mean.iloc[:,:-1]\n",
    "y_base = df_mean.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 753)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(), LinearSVC(), SVC(), KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7857687074829931; AUC: 0.7387277966225335\n",
      "Accuracy: 0.545999199679872; AUC: 0.3062753036437247\n",
      "Accuracy: 0.7460792316926771; AUC: 0.5\n",
      "Accuracy: 0.7103865546218489; AUC: 0.5919137761243025\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for c in classifiers:\n",
    "    print('Accuracy: {}; AUC: {}'.format(cross_val_score(c, X_base, y_base, cv=5, scoring='accuracy').mean(),\n",
    "                                         cross_val_score(c, X_base, y_base, cv=5, scoring='roc_auc').mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on accuracy and AUC, it seems logistic regression has the best performance, followed by SVM or kNN. Therefore, logistic regression is selected as the model for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Improvement\n",
    "\n",
    "### Adding more features\n",
    "The min and max of the attributes for each id are added into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 2257)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_min = df.groupby(['id']).min().drop(['gender', 'class'], axis=1)\n",
    "df_max = df.groupby(['id']).max().drop(['gender', 'class'], axis=1)\n",
    "df_by_patient = pd.concat([df_mean.iloc[:,:-1], df_min, df_max], axis=1, join_axes=[df_mean.index])\n",
    "df_by_patient.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_base\n",
    "#X = df_by_patient\n",
    "y = df_mean.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 753)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=252, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=252)\n",
    "pipeline = make_pipeline(scaler, pca)\n",
    "pipeline.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>variance</th>\n",
       "      <th>cumulated_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.140653</td>\n",
       "      <td>0.140653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.107907</td>\n",
       "      <td>0.248560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.099082</td>\n",
       "      <td>0.347642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>0.394802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.038141</td>\n",
       "      <td>0.432942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   features  variance  cumulated_variance\n",
       "0         0  0.140653            0.140653\n",
       "1         1  0.107907            0.248560\n",
       "2         2  0.099082            0.347642\n",
       "3         3  0.047160            0.394802\n",
       "4         4  0.038141            0.432942"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_dict = {'features': range(pca.n_components_),\n",
    "            'variance': pca.explained_variance_ratio_}\n",
    "df_pca = pd.DataFrame(pca_dict)\n",
    "df_pca['cumulated_variance'] = df_pca.variance.cumsum()\n",
    "df_pca.sort_values(['variance'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAEt5JREFUeJzt3X+sX/dd3/HnC5uYrYW0TQwqtje7\ni0FyBerSW7fTIJuIaO1Oi0GzqVO0JlMmM4H3Q4xtrthCMCARNMiGak31low0WedmYRWWcsF0y8Qk\nlGa+CWlS1zO9MVl964rc4iwsQyF18t4f32P27bf35p5779e+8ffzfEhX33M+53PO9/3RsV7nfM/5\nfo9TVUiS2vBNa12AJOnKMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDVm/1gWM\nuv7662vr1q1rXYYkXVWeeOKJr1bVxqX6veFCf+vWrczMzKx1GZJ0VUnyv/r08/KOJDXE0Jekhhj6\nktQQQ1+SGmLoS1JDDH1Jakiv0E+yK8mZJLNJDi2w/KYkTya5mGTvAsu/LcmXk3xsHEVLklZmydBP\nsg44AuwGdgC3Jtkx0u1LwO3AJxfZzM8Bv7PyMiVJ49DnTH8nMFtVZ6vqFeAYsGe4Q1U9V1VPA6+N\nrpzk3cB3AL89hnolSavQJ/Q3AeeG5ue6tiUl+Sbgl4F/svzSVmbroUeu1FtJ0lWnT+hngbbquf0f\nB6ar6tzrdUpyIMlMkpn5+fmem5YkLVefZ+/MAVuG5jcD53tu/68A35/kx4E3A9ckeamqvu5mcFUd\nBY4CTE1N9T2gSJKWqU/onwS2J9kGfBnYD3y4z8ar6kcvTSe5HZgaDXxJ0pWz5OWdqroIHAROAKeB\nh6rqVJLDSW4BSPKeJHPAPuDjSU5dzqIlSSvT69HKVTUNTI+03Tk0fZLBZZ/X28avAb+27AolSWPj\nL3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBD\nX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQXqGfZFeSM0lmkxxaYPlNSZ5McjHJ\n3qH2dyV5LMmpJE8n+dA4i5ckLc+SoZ9kHXAE2A3sAG5NsmOk25eA24FPjrT/CfCRqnonsAv4V0ne\nstqiJUkrs75Hn53AbFWdBUhyDNgDfOFSh6p6rlv22vCKVfX7Q9PnkzwPbAT+96orlyQtW5/LO5uA\nc0Pzc13bsiTZCVwDPLvcdSVJ49En9LNAWy3nTZK8HXgA+DtV9doCyw8kmUkyMz8/v5xNS5KWoU/o\nzwFbhuY3A+f7vkGSbwMeAf55VX12oT5VdbSqpqpqauPGjX03LUlapj6hfxLYnmRbkmuA/cDxPhvv\n+n8a+ERV/aeVlylJGoclQ7+qLgIHgRPAaeChqjqV5HCSWwCSvCfJHLAP+HiSU93qPwLcBNye5Knu\n712XZSSSpCX1+fYOVTUNTI+03Tk0fZLBZZ/R9R4EHlxljZKkMfEXuZLUEENfkhpi6EtSQwx9SWqI\noS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ2ZyNDfeuiRtS5Bkt6QJjL0\nJUkLM/QlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ3qFfpJdSc4kmU1yaIHlNyV5MsnFJHtHlt2W\n5Ivd323jKlyStHxLhn6SdcARYDewA7g1yY6Rbl8Cbgc+ObLu24CfAd4L7AR+JslbV1+2JGkl+pzp\n7wRmq+psVb0CHAP2DHeoqueq6mngtZF1PwB8pqouVNULwGeAXWOoW5K0An1CfxNwbmh+rmvrYzXr\nSpLGrE/oZ4G26rn9XusmOZBkJsnM/Px8z01LkparT+jPAVuG5jcD53tuv9e6VXW0qqaqamrjxo09\nN/36fOiaJH2jPqF/EtieZFuSa4D9wPGe2z8BvD/JW7sbuO/v2iRJa2DJ0K+qi8BBBmF9Gnioqk4l\nOZzkFoAk70kyB+wDPp7kVLfuBeDnGBw4TgKHuzZJ0hpY36dTVU0D0yNtdw5Nn2Rw6Wahde8D7ltF\njZKkMfEXuZLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMM\nfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1Jakiv0E+yK8mZJLNJDi2wfEOS\nT3XLH0+ytWv/5iT3J3kmyekkHx1v+ZKk5Vgy9JOsA44Au4EdwK1Jdox0uwN4oapuAO4B7u7a9wEb\nqup7gHcDP3bpgCBJuvL6nOnvBGar6mxVvQIcA/aM9NkD3N9NPwzcnCRAAW9Ksh74c8ArwB+PpXJJ\n0rL1Cf1NwLmh+bmubcE+VXUReBG4jsEB4P8CXwG+BPzLqrqwypolSSvUJ/SzQFv17LMTeBX4TmAb\n8I+TvOMb3iA5kGQmycz8/HyPkiRJK9En9OeALUPzm4Hzi/XpLuVcC1wAPgz8VlV9raqeB34XmBp9\ng6o6WlVTVTW1cePG5Y9CktRLn9A/CWxPsi3JNcB+4PhIn+PAbd30XuDRqioGl3R+IANvAt4H/M/x\nlC5JWq4lQ7+7Rn8QOAGcBh6qqlNJDie5pet2L3BdklngJ4FLX+s8ArwZ+DyDg8e/r6qnxzwGSVJP\n6/t0qqppYHqk7c6h6ZcZfD1zdL2XFmqXJK0Nf5ErSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLo\nS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4k\nNcTQl6SGGPqS1JBeoZ9kV5IzSWaTHFpg+YYkn+qWP55k69Cy703yWJJTSZ5J8i3jK1+StBxLhn6S\ndcARYDewA7g1yY6RbncAL1TVDcA9wN3duuuBB4G/V1XvBP468LWxVS9JWpY+Z/o7gdmqOltVrwDH\ngD0jffYA93fTDwM3JwnwfuDpqvocQFX9UVW9Op7SJUnL1Sf0NwHnhubnurYF+1TVReBF4Drgu4BK\nciLJk0n+6UJvkORAkpkkM/Pz88sdgySppz6hnwXaqmef9cD3AT/avf5wkpu/oWPV0aqaqqqpjRs3\n9ihJkrQSfUJ/DtgyNL8ZOL9Yn+46/rXAha79d6rqq1X1J8A0cONqi5YkrUyf0D8JbE+yLck1wH7g\n+Eif48Bt3fRe4NGqKuAE8L1J/nx3MPhrwBfGU7okabnWL9Whqi4mOcggwNcB91XVqSSHgZmqOg7c\nCzyQZJbBGf7+bt0XkvwKgwNHAdNV9chlGoskaQlLhj5AVU0zuDQz3Hbn0PTLwL5F1n2Qwdc2JUlr\nzF/kSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakh\nhr4kNWSiQ3/rIZ/iLEnDJjr0JUlfz9CXpIYY+pLUEENfkhpi6EtSQwx9SWpIr9BPsivJmSSzSQ4t\nsHxDkk91yx9PsnVk+V9I8lKSnxpP2ZKklVgy9JOsA44Au4EdwK1Jdox0uwN4oapuAO4B7h5Zfg/w\nm6svV5K0Gn3O9HcCs1V1tqpeAY4Be0b67AHu76YfBm5OEoAkPwScBU6Np2RJ0kr1Cf1NwLmh+bmu\nbcE+VXUReBG4LsmbgH8G/OzqS5UkrVaf0M8CbdWzz88C91TVS6/7BsmBJDNJZubn53uUJElaifU9\n+swBW4bmNwPnF+kzl2Q9cC1wAXgvsDfJLwFvAV5L8nJVfWx45ao6ChwFmJqaGj2gSJLGpE/onwS2\nJ9kGfBnYD3x4pM9x4DbgMWAv8GhVFfD9lzokuQt4aTTwJUlXzpKhX1UXkxwETgDrgPuq6lSSw8BM\nVR0H7gUeSDLL4Ax//+UsWpK0Mn3O9KmqaWB6pO3OoemXgX1LbOOuFdQnSRojf5ErSQ0x9CWpIYa+\nJDWkmdD3v06UpIZCX5Jk6EtSUwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JCmQt8faElqXVOh\nL0mtM/QlqSGGviQ1xNCXpIY0F/rezJXUsuZCX5JaZuhLUkMMfUlqSK/QT7IryZkks0kOLbB8Q5JP\ndcsfT7K1a//BJE8keaZ7/YHxlr8yXteX1KolQz/JOuAIsBvYAdyaZMdItzuAF6rqBuAe4O6u/avA\n36yq7wFuAx4YV+GSpOXrc6a/E5itqrNV9QpwDNgz0mcPcH83/TBwc5JU1e9V1fmu/RTwLUk2jKNw\nSdLy9Qn9TcC5ofm5rm3BPlV1EXgRuG6kz98Cfq+q/nT0DZIcSDKTZGZ+fr5v7ZKkZeoT+lmgrZbT\nJ8k7GVzy+bGF3qCqjlbVVFVNbdy4sUdJ4+G1fUmt6RP6c8CWofnNwPnF+iRZD1wLXOjmNwOfBj5S\nVc+utmBJ0sr1Cf2TwPYk25JcA+wHjo/0Oc7gRi3AXuDRqqokbwEeAT5aVb87rqIlSSuzZOh31+gP\nAieA08BDVXUqyeEkt3Td7gWuSzIL/CRw6WudB4EbgH+R5Knu79vHPgpJUi/r+3SqqmlgeqTtzqHp\nl4F9C6z388DPr7LGy2rroUd47hf/xlqXIUlXhL/IlaSGGPr4LR5J7TD0Owa/pBYY+kMMfkmTztBf\ngOEvaVIZ+osw+CVNIkNfkhpi6L8Oz/YlTRpDfwkGv6RJYuj3YPBLmhSG/jIY/pKudob+Mhn8kq5m\nhv4KbD30iOEv6apk6K+CwS/patPr0cp6fcPh72OaJb2ReaY/ZsMHAD8JSHqj8Uz/MvNTgKQ3EkP/\nClvo7N+DgaQrxdB/g1jsYOB/5yhpnAz9q8DoAeHSwWC0TZKW0iv0k+wC/jWwDvh3VfWLI8s3AJ8A\n3g38EfChqnquW/ZR4A7gVeAfVNWJsVWvb9DnALFYuwcOafItGfpJ1gFHgB8E5oCTSY5X1ReGut0B\nvFBVNyTZD9wNfCjJDmA/8E7gO4H/kuS7qurVcQ9Eq3fpUtJyDhIeUKSrS58z/Z3AbFWdBUhyDNgD\nDIf+HuCubvph4GNJ0rUfq6o/Bf4gyWy3vcfGU76uFss9oCzWPo5tLNTuQUmt6BP6m4BzQ/NzwHsX\n61NVF5O8CFzXtX92ZN1NK65WukyGb5hfqQPNpbZJek8Pnm98qarX75DsAz5QVX+3m//bwM6q+vtD\nfU51fea6+WcZnNEfBh6rqge79nuB6ar69ZH3OAAc6Ga/GzizijFdD3x1FetfjVobs+OdfK2NeRzj\n/YtVtXGpTn3O9OeALUPzm4Hzi/SZS7IeuBa40HNdquoocLRHLUtKMlNVU+PY1tWitTE73snX2piv\n5Hj7PIbhJLA9ybYk1zC4MXt8pM9x4LZuei/waA0+QhwH9ifZkGQbsB34H+MpXZK0XEue6XfX6A8C\nJxh8ZfO+qjqV5DAwU1XHgXuBB7obtRcYHBjo+j3E4KbvReAn/OaOJK2dXt/Tr6ppYHqk7c6h6ZeB\nfYus+wvAL6yixuUay2Wiq0xrY3a8k6+1MV+x8S55I1eSNDl8tLIkNWSiQj/JriRnkswmObTW9VwO\nSZ5L8kySp5LMdG1vS/KZJF/sXt+61nWuRpL7kjyf5PNDbQuOMQO/2u3zp5PcuHaVr8wi470ryZe7\n/fxUkg8OLftoN94zST6wNlWvXJItSf5bktNJTiX5h137JO/jxcZ85fdzVU3EH4ObzM8C7wCuAT4H\n7Fjrui7DOJ8Drh9p+yXgUDd9CLh7retc5RhvAm4EPr/UGIEPAr8JBHgf8Pha1z+m8d4F/NQCfXd0\n/7Y3ANu6f/Pr1noMyxzv24Ebu+lvBX6/G9ck7+PFxnzF9/Mknen/2eMiquoV4NLjIlqwB7i/m74f\n+KE1rGXVquq/M/gW2LDFxrgH+EQNfBZ4S5K3X5lKx2OR8S7mzx5tUlV/AFx6tMlVo6q+UlVPdtP/\nBzjN4Jf6k7yPFxvzYi7bfp6k0F/ocRGT+MiHAn47yRPdL5kBvqOqvgKDf1zAt69ZdZfPYmOc5P1+\nsLuccd/QJbuJGm+SrcBfBh6nkX08Mma4wvt5kkI/C7RN4leT/mpV3QjsBn4iyU1rXdAam9T9/m+A\nvwS8C/gK8Mtd+8SMN8mbgV8H/lFV/fHrdV2gbVLGfMX38ySFfq9HPlztqup89/o88GkGH/n+8NLH\n3e71+bWr8LJZbIwTud+r6g+r6tWqeg34t/z/j/YTMd4k38wg/P5DVf3nrnmi9/FCY16L/TxJod/n\ncRFXtSRvSvKtl6aB9wOf5+sfg3Eb8BtrU+FltdgYjwMf6b7h8T7gxUuXCK5mI9esf5jBfoYJeLRJ\nkjD4Ff/pqvqVoUUTu48XG/Oa7Oe1vqs95jvkH2RwV/xZ4KfXup7LML53MLij/zng1KUxMniM9X8F\nvti9vm2ta13lOP8jg4+6X2NwxnPHYmNk8DH4SLfPnwGm1rr+MY33gW48T3cB8Pah/j/djfcMsHut\n61/BeL+PwaWKp4Gnur8PTvg+XmzMV3w/+4tcSWrIJF3ekSQtwdCXpIYY+pLUEENfkhpi6EtSQwx9\nSWqIoS9JDTH0Jakh/w/BPWtWMjABlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a98fd2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add plot\n",
    "plt.bar(df_pca['features'], df_pca['variance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 252) 252\n",
      "First 146 principle factors explains over 95% of the variance\n"
     ]
    }
   ],
   "source": [
    "print(range(pca.n_components_), len(pca.explained_variance_))\n",
    "print('First {} principle factors explains over 95% of the variance'.format(sum(df_pca.cumulated_variance > 0.95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline and Grid Search\n",
    "In the new process, scaling is added as part of the modeling pipeline. Grid search is also used to find out the best parameters for the components of PCA and regularization of logistic regression. Finally, the model performance is tested with hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogReg__penalty': 'l1', 'PCA__n_components': 20, 'LogReg__C': 0.13894954943731375} 0.847682119205\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('PCA', PCA()),\n",
    "                     ('LogReg', LogisticRegression())])\n",
    "n_components = np.arange(10, 200, 10)\n",
    "c_space = np.logspace(-2, 2, 15)\n",
    "parameters = {'PCA__n_components': n_components,\n",
    "              'LogReg__C': c_space,\n",
    "              'LogReg__penalty': ['l1', 'l2']}\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_params_, cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8613861386138614\n",
      "AUC: 0.8666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = cv.predict_proba(X_test)[:,1]\n",
    "print('Accuracy: {}\\nAUC: {}'.format(cv.score(X_test, y_test), roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('PCA', PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('LogReg', LogisticRegression(C=0.13894954943731375, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same process without Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([('PCA', PCA()),\n",
    "                     ('LogReg', LogisticRegression())])\n",
    "n_components = np.arange(10, 200, 10)\n",
    "c_space = np.logspace(-2, 2, 15)\n",
    "parameters = {'PCA__n_components': n_components,\n",
    "              'LogReg__C': c_space,\n",
    "              'LogReg__penalty': ['l1', 'l2']}\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_params_, cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same process without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LogReg__penalty': 'l1', 'LogReg__C': 0.12689610031679222} 0.82119205298\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('LogReg', LogisticRegression())])\n",
    "c_space = np.logspace(-2, 2, 30)\n",
    "parameters = {'LogReg__C': c_space,\n",
    "              'LogReg__penalty': ['l1', 'l2']}\n",
    "cv2 = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv2.fit(X_train, y_train)\n",
    "print(cv2.best_params_, cv2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8514851485148515\n",
      "AUC: 0.8646153846153847\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob2 = cv2.predict_proba(X_test)[:,1]\n",
    "print('Accuracy: {}\\nAUC: {}'.format(cv2.score(X_test, y_test), roc_auc_score(y_test, y_pred_prob2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl0VFXa/v3vNmGQFhwABZlCAoFU\nEo0SicwgyiAgOGCjNipPBIFWaX3RFgcEWhEZREGQeXCKCo8MCo9iKzSCCkaaQYJACIGEQUKasRHI\nsH9/JOSNEEgFqnKqKtdnrayVqtp16jok3Gz2Oec+xlqLiIgElsucDiAiIp6n4i4iEoBU3EVEApCK\nu4hIAFJxFxEJQCruIiIBSMVdRCQAqbiLiAQgFXcRkQAU7NQHV6tWzYaEhDj18SIifunnn38+aK2t\nXtw4x4p7SEgIiYmJTn28iIhfMsbscmeclmVERAKQiruISABScRcRCUAq7iIiAUjFXUQkABVb3I0x\ns4wxB4wxv5zndWOMmWCMSTbGbDTG3Oz5mCIiUhLuzNznAJ0u8HpnoGH+Vz/g3UuPJSIil6LY89yt\ntSuNMSEXGNIdeM/m3a/vR2PMVcaYmtbafR7KKCI+4KM1u1m0fo9bY9ufWEqL35d7OZEfspBrc/nv\nNZHcOnC6Vz/KE2vutYC0Qo/T8587hzGmnzEm0RiTmJGR4YGPFpHSsmj9HpL2HXVrbIvflxOSleLl\nRP4lOzubY8eOceK/J6AU7l3tiStUTRHPFZncWjsNmAYQGxurO3OL+BlXzSp88niz4gfOvhK4icg+\nS7yeydcdPnyYZ599lhkzZtCgQQNmzJhBmzZtvP65niju6UCdQo9rA3s9sF0R8aKSLLMAJO07iqtm\nFS8mCjw5OTk0b96crVu38txzzzFs2DAuv/zyUvlsTxT3xcATxpiPgTjgiNbbRXzfmWUWdwu2q2YV\nuscUueIqZ8nMzOSaa64hKCiI1157jTp16hAbG1uqGYot7saYBKAtUM0Ykw68ApQDsNZOAZYCdwLJ\nwAmgj7fCiohnub3MIm6x1vLhhx8yaNAgRo0aRd++fbn77rsdyeLO2TIPFPO6Bf7qsUQiDirpUkVJ\n+dJZJINP51CpfFD++riH7d8ENaI9v10flpaWRv/+/Vm6dCm33norLVq0cDSPrlAVKaQkZ4RcDF86\ni6RS+SCqXVHBOxuvEQ3R93ln2z4oISGByMhIVqxYwVtvvcWqVatwuVyOZnKsn7vIRUucDZvmuz38\nt2MnOXj8lFtjz8xmI8t7YTYLYHZDXZ1FEmiuvvpq4uLimDZtGvXr13c6DqCZu/ijTfPz/tvvpoPH\nT3HidI5bY706m4UyN6MNVNnZ2YwZM4bXXnsNgE6dOrFs2TKfKeygmbv4qxrR4Obsd8TUHwB04FA8\nYsOGDcTHx/Pzzz9z//33Y63FGIMxRV3y4xwVd3HcmnnjuGL7ArfHh2SlkFoutKBoF0fnZ4snnDp1\nildffZVRo0ZxzTXXMG/ePO69916fK+pnaFlGHHfF9gXUOb3D7fGp5UJZfXk7t8fr/GzxhO3bt/PG\nG2/w4IMPkpSUxH333eezhR00cxc3lfQUwZKc8lfn9A7SyocR+cIqt7cfSV4LUhFvOn78OIsWLeKh\nhx4iKiqKX3/9ldDQUKdjuUUzd3FLSU8RLMkpf2nlwzje0JkLPUTO5+uvvyY6OprevXuzZcsWAL8p\n7KCZu5RAia5mVOMo8VOHDh1i8ODBzJo1i/DwcP71r38RERHhdKwSU3EXEcmXk5NDixYt2LZtG0OG\nDGHo0KFUrFjR6VgXRcVdRMq8gwcPFjT6GjlyJHXr1uXmm/37jqFacxeRMstay3vvvUd4eDgzZswA\noEePHn5f2EHFXUTKqF27dtG5c2ceeeQRIiIiaN26tdORPErFXUTKnA8++ICoqChWrVrFxIkT+e67\n72jcuLHTsTxKa+4iUuZUr16dFi1aMHXqVOrVq+d0HK9QcReRgJeVlcW4cePIysri5ZdfpmPHjnTo\n0MGnrzC9VFqWEZGA9u9//5u4uDiGDBlCUlISefcXIqALO2jmLm4qaCfg7l17yuCdeMS3nDx5khEj\nRjB69GiqVavG//7v/3LPPfc4HavUaOYubinxHYTUt1wclpyczNixY3n44YfZsmVLmSrsoJm7lEBq\nuVC1ExCfdvz4cRYsWEDv3r2Jiopi69atPnUDjdKkmbuIBISvvvqKyMhIHnnkkYJGX2W1sIOKu4j4\nuczMTB555BE6depEpUqV+O677/yy0ZenaVlGRPzWmUZfycnJvPjii7z00kt+2+jL01TcRcTvZGRk\nULVqVYKCgnjjjTeoV68eMTExTsfyKVqWERG/Ya1l9uzZhIeHM336dAC6d++uwl4EFXcR8Qupqal0\n7NiR//mf/yE6Opp27dy/j25ZpOIuIj7v/fffJyoqih9++IHJkyezYsUKwsPDnY7l07TmLiI+77rr\nrqN169ZMmTKFunXrOh3HL6i4i4jPycrKYvTo0eTk5DB06FA6dOhAhw4dnI7lV7QsIyI+Zd26ddxy\nyy289NJLbN26taDRl5SMWzN3Y0wn4G0gCJhhrR111ut1gbnAVfljnrfWLvVwVvGgNfPGccX2BW6P\nr3N6B2nlw7yYSMq633//neHDhzN27FiqV6/OggUL6NGjh9Ox/FaxM3djTBAwCegMuIAHjDGus4a9\nBHxqrb0J6AVM9nRQ8awrti+gzukdbo9PKx/G8YZ3ezGRlHUpKSm8+eabPProoyQlJamwXyJ3Zu5N\ngWRrbQqAMeZjoDuQVGiMBarkf38lsNeTIcU70sqHEfnCKqdjSBl29OhRPvvsMx599FEiIyPZvn17\nwN4ZqbS5U9xrAWmFHqcDcWeNGQYsM8Y8CfwJuN0j6aRESrLUomUWcdrSpUvp378/e/bsIS4ujoiI\nCBV2D3LngGpRtys5+wjHA8Aca21t4E7gfWPMOds2xvQzxiQaYxIzMjJKnlYuqCRLLVpmEaccPHiQ\n3r1706VLFypXrszq1avV6MsL3Jm5pwN1Cj2uzbnLLvFAJwBr7Q/GmIpANeBA4UHW2mnANIDY2Fgd\nAvcCLbWILzvT6CslJYWhQ4fywgsvUKFCBadjBSR3ivtPQENjTH1gD3kHTB88a8xuoD0wxxgTAVQE\nNDUXEQB+++03qlevTlBQEGPHjqVevXrccMMNTscKaMUuy1hrs4EngK+ALeSdFbPZGDPCGHNX/rD/\nD+hrjNkAJACPWp2cKlLmWWuZOXMmjRo1Ytq0aQB069ZNhb0UuHWee/4560vPem5ooe+TgBaejRaA\nEmfDpvle23xIVgqp5UK9tn2RkkhJSaFv3758++23tGnThttv13kWpUlXqJamTfNh/yavbT61XCir\nL1enPHHe3LlziY6O5qeffmLKlCl8++23NGjQwOlYZYp6y5S2GtHgpZtMj5j6AwD9vLJ1Efddf/31\n3Hbbbbz77rvUrl3b6Thlkoq7iFyy06dPM2rUKHJzcxk2bBh33HEHd9xxh9OxyjQty4jIJfnpp59o\n0qQJr7zyCikpKWr05SM0c/dhH63ZzaL1e9wen7TvKK6aVYofKOIBJ06cYOjQoYwfP56aNWuyePFi\nunXr5nQsyaeZuw9btH4PSfuOuj3eVbMK3WNqeTGRyP9v586dTJw4kb59+7J582YVdh+jmbuPc9Ws\nwiePN3M6hggAR44c4bPPPqNPnz5ERkaSnJxMnTp1in+jlDrN3EXELUuWLCEyMpLHHnuMX3/9FUCF\n3YepuIvIBWVkZPDQQw/RtWtXrr76an744QcaN27sdCwphpZlROS8cnJyaNmyJTt37mT48OE8//zz\nlC9f3ulY4gYVdxE5x/79+7n22msJCgpi3LhxhISEEBUV5XQsKQEty4hIgdzcXKZOnUp4eDhTp04F\noGvXrirsfkjFXUQASE5Opn379vTv359bbrmFjh07Oh1JLoGKu4gwe/ZsoqOjWbduHdOnT+ef//wn\noaHqMOrPtOYuItStW5eOHTsyadIkatXShXCBQMVdpAw6deoUr7/+Orm5uYwYMYL27dvTvn17p2OJ\nB2lZRqSMWbNmDU2aNGH48OHs3r1bjb4ClIq7SBnx3//+l2eeeYZmzZpx5MgRvvjiC+bMmYMxxulo\n4gUq7iJlxK5du5g8eTL9+/dn8+bNdOnSxelI4kVacxcJYIcPH2b+/Pk89thjuFwukpOTdWekMkIz\nd5EAtWjRIlwuF/379y9o9KXCXnaouIsEmAMHDtCrVy969OhB9erV+fHHH9XoqwzSsoxIAMnJyaFF\nixbs3r2bV199leeee45y5co5HUscoOIuEgD27t1LjRo1CAoK4u233yYkJASXy+V0LHGQlmVE/Fhu\nbi7vvvsujRs3ZsqUKQDceeedKuyi4i7ir7Zt20a7du0YOHAgcXFxdO7c2elI4kNU3EX80MyZM7nx\nxhvZuHEjs2bNYtmyZdSvX9/pWOJDtOYu4odCQkLo3LkzkyZNombNmk7HER+k4i7iB06dOsU//vEP\nAF599VU1+pJiaVlGxMd9//33xMTE8Nprr7Fv3z41+hK3qLiL+Kjjx48zaNAgWrZsyYkTJ/jyyy+Z\nOXOmGn2JW9xaljHGdALeBoKAGdbaUUWMuR8YBlhgg7X2QQ/mLD2Js2HTfO9se/8mqBHtnW1LwNm9\nezdTp07lr3/9KyNHjqRy5cpORxI/UmxxN8YEAZOAO4B04CdjzGJrbVKhMQ2BIUALa+0hY8y13grs\ndZvme68I14iG6Ps8v10JGIcOHWLevHn069cPl8tFSkoK119/vdOxxA+5M3NvCiRba1MAjDEfA92B\npEJj+gKTrLWHAKy1BzwdtFTViIY+S5xOIWXMggULGDhwIBkZGbRp04ZGjRqpsMtFc2fNvRaQVuhx\nev5zhYUD4caY1caYH/OXcc5hjOlnjEk0xiRmZGRcXGKRALN//3569uzJPffcQ40aNVi7di2NGjVy\nOpb4OXdm7kUdvTn7cH0w0BBoC9QGvjPGRFlrD//hTdZOA6YBxMbG6pC/lHk5OTm0atWKtLQ0Ro4c\nyeDBg9XoSzzCneKeDtQp9Lg2sLeIMT9aa7OAncaYreQV+588klIkwKSnp3P99dcTFBTEhAkTqF+/\nvtryike5syzzE9DQGFPfGFMe6AUsPmvMQqAdgDGmGnnLNCmeDCoSCHJzc5k4cSKNGzfm3XffBaBz\n584q7OJxxRZ3a2028ATwFbAF+NRau9kYM8IYc1f+sK+ATGNMErAceNZam+mt0CL+6Ndff6V169Y8\n9dRTtGzZkq5duzodSQKYW+e5W2uXAkvPem5ooe8t8Ez+l5zHR2t2s2j9HrfHJ+07iqtmFS8mktIy\nY8YMnnjiCSpVqsTcuXPp3bu3LkYSr9IVqqVo0fo9JO076vZ4V80qdI85+8Qk8UdhYWF069aNLVu2\n8PDDD6uwi9epcdhZfjt2koPHTzFi6g8e3/aZmfgnjzfz+LbFt5w8eZIRI0YAMHLkSNq1a0e7du0c\nTiVliWbuZzl4/BQnTud4ZduaiZcNq1evJiYmhtdff52MjAw1+hJHaOZehErlgzS7lhI7duwYL7zw\nApMmTaJevXp89dVXdOjQwelYUkZp5i7iIenp6cyYMYMnn3ySTZs2qbCLozRzF7kEmZmZfPrppwwY\nMICIiAhSUlJ0ZyTxCZq5i1wEay3z58/H5XLx1FNPsXXrVgAVdvEZKu4iJbRv3z7uvfdeevbsSZ06\ndUhMTFSjL/E5WpYRKYEzjb727NnD6NGjefrppwkO1l8j8T36rRRxQ1paGrVq1SIoKIhJkyZRv359\nwsPDnY4lcl5alhG5gJycHCZMmPCHRl8dO3ZUYRefp5m7yHls2bKF+Ph4fvjhBzp37ky3bt2cjiTi\nNs3cRYowbdo0YmJi2LZtG++//z5Lliyhbt26TscScZtm7iJFaNiwIXfffTcTJkzg2mv9937vUnYF\nfHEvaZvdwadzqFQ+yIuJxBf9/vvvDBs2DGMMo0aNUqMv8XsBvyxT0ja7lcoHUe2KCl5MJL5m5cqV\n3HjjjYwePZojR46o0ZcEhICfuQMla7M7+0rvhhGfcfToUZ5//nneffddQkND+eabb7jtttucjiXi\nEQE/cxc5n7179zJnzhyeeeYZNm7cqMIuAaVMzNxFzjh48CCffvopAwcOpHHjxuzcuZPrrrvO6Vgi\nHqeZu5QJ1lo++eQTXC4Xf/vb39i2bRuACrsELBV3CXh79+6lR48e9OrVi3r16vHzzz/rClMJeFqW\nkYCWk5ND69at2bNnD2PHjmXQoEFq9CVlgn7LJSDt2rWL2rVrExQUxOTJkwkNDaVBgwZOxxIpNVqW\nkYCSk5PDm2++SUREREGjrw4dOqiwS5mjmbsEjF9++YX4+HjWrl1L165d6dGjh9ORRByjmbsEhClT\npnDzzTeTkpLCRx99xOLFi6ldu7bTsUQco+Iufu1Mq4CIiAh69uxJUlISDzzwAMYYh5OJOEvLMuKX\nTpw4wdChQwkKCuKNN96gTZs2tGnTxulYIj5DM3fxOytWrOCGG25g3LhxHD9+XI2+RIqg4i5+48iR\nIzz++OMFrXi//fZbJk2apCUYkSK4tSxjjOkEvA0EATOstaPOM+4+YB5wi7U20WMpCylpf/akfUdx\n1azijShSyvbt28cHH3zA4MGDGT58OJUqVXI6kojPKnbmbowJAiYBnQEX8IAxxlXEuMrAU8AaT4cs\nrKT92V01q9A9ppYXE4k3ZWRkMHHiRAAaN25MamoqY8aMUWEXKYY7M/emQLK1NgXAGPMx0B1IOmvc\nP4DRwGCPJixCifqzi1+y1pKQkMBTTz3F0aNH6dixI+Hh4VSvXt3paCJ+wZ3iXgtIK/Q4HYgrPMAY\ncxNQx1r7hTHG68W9RBJnw6b57o/fvwlqRHsvjxQrLS2NAQMGsGTJEuLi4pg5c6YafYmUkDvFvaij\nVQWnJxhjLgPGA48WuyFj+gH9gNK7k/ym+SUr2DWiIfo+72aS88rOzqZt27bs37+f8ePH8+STTxIU\npHvaipSUO8U9HahT6HFtYG+hx5WBKGBF/lkLNYDFxpi7zj6oaq2dBkwDiI2NLb3z12pEQ58lpfZx\nUnKpqanUqVOH4OBgpk6dSmhoKKGhoU7HEvFb7pwK+RPQ0BhT3xhTHugFLD7zorX2iLW2mrU2xFob\nAvwInFPYRYqSnZ3N2LFjiYiIYPLkyQDcfvvtKuwil6jYmbu1NtsY8wTwFXmnQs6y1m42xowAEq21\niy+8BZGibdy4kfj4eBITE+nevTv33nuv05FEAoZb57lba5cCS896buh5xra99FgS6CZPnsygQYO4\n+uqr+eSTT+jZs6cuRhLxIF2hKqXqTKuAqKgoevXqRVJSEvfff78Ku4iHqXGYlIr//ve/vPTSSwQH\nBzNmzBhat25N69atnY4lErA0cxev++abb4iOjuatt97i1KlTavQlUgpU3MVrDh8+zGOPPcbtt99O\ncHAwK1euZMKECVqCESkFKu7iNb/99hsff/wxf//739mwYQOtWrVyOpJImaE1d/GoMwV90KBBNGrU\niNTUVKpVq+Z0LJEyRzN38QhrLR988AEul4vnnnuO7du3A6iwizhExV0u2e7du+nSpQu9e/emUaNG\nrF+/noYNGzodS6RM07KMXJIzjb4OHDjAhAkTGDhwoBp9ifgAFXe5KCkpKdSrV4/g4GCmT59OWFgY\nISEhTscSkXxalpESyc7O5o033sDlcjFp0iQA2rdvr8Iu4mM0cxe3rV+/nvj4eNatW8fdd99Nz549\nnY4kIuehmbu45Z133uGWW25hz549zJ8/n88++4yaNWs6HUtEzkPFXS7oTKuAG264gYceeoikpCS1\n5hXxA1qWkSIdP36cF198kXLlyjF27Fg1+hLxM5q5yzmWLVtGVFQUEydOJCsrS42+RPyQirsUOHTo\nEH369KFjx45UrFiRlStX8vbbb6vRl4gfUnGXAgcOHGD+/PkMGTKE9evX07JlS6cjichF0pp7Gbd/\n/34SEhJ4+umnCxp9Va1a1elYInKJNHMvo6y1zJ07F5fLxZAhQwoafamwiwQGFfcyKDU1lU6dOvHo\no4/icrnU6EskAGlZpozJzs6mXbt2HDx4kEmTJtG/f38uu0z/xosEGhX3MiI5OZn69esTHBzMrFmz\nCA0NpV69ek7HEhEv0ZQtwGVlZTFy5EgiIyMLGn21a9dOhV0kwGnmHsDWrVtHfHw869evp2fPnvz5\nz392OpKIlBLN3APUhAkTaNq0Kfv37+ezzz7j008/5brrrnM6loiUEhX3AHOmVcBNN93Eww8/TFJS\nEnfffbfDqUSktGlZJkAcO3aMIUOGUKFCBcaNG0erVq1o1aqV07FExCF+V9zbn1hKi9+Xw+wr3XvD\n/k1QI9q7oRz25Zdf8vjjj5OWlsbf/vY3rLXqByNSxvndskyL35cTkpXi/htqREP0fd4L5KDMzEwe\neeQROnfuzJ/+9CdWr17Nm2++qcIuIv43cwdILRdKZJ8lTsdwXGZmJgsWLODll1/mxRdfpEKFCk5H\nEhEf4dbM3RjTyRiz1RiTbIx5vojXnzHGJBljNhpjvjHG6CRqL9m3bx9jx47FWkt4eDi7du1ixIgR\nKuwi8gfFFndjTBAwCegMuIAHjDGus4b9G4i11t4AzAdGezpoWWetZdasWURERPDyyy+TnJwMwNVX\nX+1wMhHxRe7M3JsCydbaFGvtaeBjoHvhAdba5dbaE/kPfwRqezZm2bZz5046dOhAfHw8N954Ixs2\nbFCjLxG5IHfW3GsBaYUepwNxFxgfD/xfUS8YY/oB/QDq1q3rZsSyLTs7m9tuu43MzEzeffdd+vXr\np0ZfIlIsd4p7UadeFHlTTWPMX4BYoE1Rr1trpwHTAGJjY3VjzgvYvn07oaGhBAcHM3v2bMLCwqhT\np47TsUTET7gzBUwHCleV2sDeswcZY24HXgTustae8ky8sicrK4tXX32VqKgo3nnnHQDatm2rwi4i\nJeLOzP0noKExpj6wB+gFPFh4gDHmJmAq0Mlae8DjKcuIxMRE4uPj2bhxI7169eKBBx5wOpKI+Kli\nZ+7W2mzgCeArYAvwqbV2szFmhDHmrvxhY4ArgHnGmPXGmMVeSxyg3n77beLi4jh48CCLFi0iISGB\na6+91ulYIuKn3LqIyVq7FFh61nNDC31/u4dzlRlnWgXExsYSHx/P6NGjueqqq5yOJSJ+zi+vUA0E\nR48e5e9//zsVK1Zk/PjxtGjRghYtWjgdS0QChM6pc8DSpUuJjIxk2rRpBAcHF7TpFRHxFBX3UnTw\n4EH+8pe/0KVLF6688kq+//57xowZo0ZfIuJxKu6l6NChQ3z++ee88sorrFu3jri4C10LJiJy8bTm\n7mV79uzhww8/5Nlnn6Vhw4bs2rVLB0xFxOs0c/cSay3Tp0/H5XIxbNgwduzYAaDCLiKlQjN3L9ix\nYwd9+/Zl+fLltG3blunTp9OgQQOnY0kZlJWVRXp6OidPnnQ6ipRQxYoVqV27NuXKlbuo96u4e1h2\ndjbt27fnP//5D1OnTuWxxx5Toy9xTHp6OpUrVyYkJEQH7v2ItZbMzEzS09OpX7/+RW1Dxd1Dtm7d\nSlhYGMHBwcydO5ewsDBq11bnY3HWyZMnVdj9kDGGqlWrkpGRcdHb0JTyEp0+fZrhw4cTHR3NpEmT\nAGjTpo0Ku/gMFXb/dKk/NxX3S7B27VqaNGnCsGHD6NmzJw899JDTkUR8zhVXXHHOc8OGDaNWrVrE\nxMTgcrlISEi4qG0vXryYUaNGAbBw4UKSkpIKXmvbti2JiYkXfH9qaiqXX355QY7+/fuTm5sLwLZt\n27jzzjtp0KABERER3H///fz2228F7x00aBC1atUqGO9rVNwv0ltvvUWzZs0Kzl3/8MMPqVatmtOx\nRPzG008/zfr161m0aBGPP/44WVlZJd7GXXfdxfPP593W+ezi7q6wsDDWr1/Pxo0bSUpKYuHChZw8\neZIuXbowYMAAkpOT2bJlCwMGDChYJsnNzWXBggXUqVOHlStXlvgzS4OKewmdaRXQtGlT+vbty+bN\nm+natavDqUT8V8OGDalUqRKHDh36w/M5OTmEhoZireXw4cNcdtllBYW0VatWJCcnM2fOHJ544gm+\n//57Fi9ezLPPPktMTEzBqcfz5s2jadOmhIeH8913310wR3BwMM2bNyc5OZmPPvqIZs2a0a1bt4LX\n27VrR1RUFADLly8nKiqKAQMGXPT/OrxNB1TddOTIEZ577jkuv/xy3nrrLZo3b07z5s2djiXituGf\nbyZp71GPbtN1fRVe6RZ5SdtYt24dDRs2PKfFdVBQEOHh4SQlJbFz506aNGnCd999R1xcHOnp6TRo\n0IBVq1YB0Lx5c+666y66du3KfffdV7CN7Oxs1q5dy9KlSxk+fDj//Oc/z5vjxIkTfPPNN4wYMYKv\nv/6aJk2anHdsQkICDzzwAN27d+eFF14gKyvrok9Z9BbN3N3w+eef43K5mDFjBhUqVFCjLxEPGD9+\nPI0aNSIuLo5hw4YVOaZVq1asXLmSlStXMmTIEFatWsVPP/3ELbfc4tZn3HPPPQA0adKE1NTUIsfs\n2LGDmJgYWrRoQZcuXejcufMFt3n69GmWLl1Kjx49qFKlCnFxcSxbtsytPKVJM/cLyMjIYNCgQSQk\nJBAdHc3ChQvd/qUS8TWXOsP2tKeffprBgwfz2Wef8fDDD7Njxw4qVqz4hzGtWrViypQp7N27lxEj\nRjBmzBhWrFhB69at3fqMChUqAHn/C8jOzi5yzJk198IiIyP517/+VeT4L7/8kiNHjhAdHQ3kzfgr\nVapEly5d3MpUWjRzv4AjR44U/HcuMTFRhV3EC+655x5iY2OZO3fuOa/FxcXx/fffc9lll1GxYkVi\nYmKYOnUqrVq1Omds5cqVOXbsmEcyPfjgg3z//fcsWbKk4Lkvv/ySTZs2kZCQwIwZM0hNTSU1NZWd\nO3eybNkyTpw44ZHP9hQV97OkpaXx+uuvY62lQYMG7Nq1i6FDh1K+fHmno4n4pRMnTlC7du2Crzff\nfPOcMUOHDuXNN98857TCChWMvf73AAAKD0lEQVQqUKdOHW699VYgbyZ/7NixgllzYb169WLMmDHc\ndNNNBQdUL9bll1/OF198wcSJE2nYsCEul4s5c+ZQpUoVvvrqqz/M0v/0pz/RsmVLPv/880v6TE8z\nTq0fx8bG2uLOQS3K5pEtAYh8YZVH8+Tm5jJt2jSee+45cnJy2LBhg/rBiN/bsmULERERTseQi1TU\nz88Y87O1Nra492rmDmzfvp3bbruNAQMG0LRpUzZt2qTCLiJ+rcwfUM3OzuaOO+7g8OHDzJw5kz59\n+uhybRHxe2W2uG/ZsoWGDRsSHBzM+++/T1hYGNdff73TsUREPKLMLcucOnWKV155hRtuuIF33nkH\nyDtIo8IuIoGkTM3cf/zxR+Lj40lKSqJ379707t3b6UgiIl5RZmbu48aNo3nz5hw7doylS5fy3nvv\nUbVqVadjiYh4RcAX9zPnzTZr1oz+/fvzyy+/FHt5sYh4ji+3/HXXyJEjz/taSEgI0dHR3HjjjXTo\n0IH9+/cDcPz4cR5//HHCwsKIjIykdevWrFmzpuB9CxYswBjDr7/+6pGMZwvY4n748GHi4+MZNGgQ\nkNdYaPLkyVSpUsXhZCICvtPy1x0XKu6Q1yVyw4YNxMbGFox97LHHuOaaa9i+fTubN29mzpw5HDx4\nsOA9CQkJtGzZko8//tgrmQOyuC9cuBCXy8XcuXOpXLmyGn2J+LDSbvl78uRJ+vTpQ3R0NDfddBPL\nly8HKNjWGV27dmXFihU8//zz/P7778TExBR7Q57WrVuTnJzMjh07WLNmDa+++mrBPZRDQ0MLrmw9\nfvw4q1evZubMmV4r7gF1QPXAgQM88cQTzJs3j5iYGL744gtuvvlmp2OJ+Ib/ex72b/LsNmtEQ+dR\nl7SJ0m75e+Z2mJs2beLXX3+lQ4cObNu27bz5Ro0axTvvvHNOc7GifPHFF0RHR7N582ZiYmIICgoq\nctzChQvp1KkT4eHhXHPNNaxbt87jtSqgZu5Hjx7l66+/5rXXXmPt2rUq7CI+zKmWv6tWrSo4U65x\n48bUq1fvgsXdHe3atSMmJoajR48yZMiQYscnJCTQq1cvIK8njjdu+OHWzN0Y0wl4GwgCZlhrR531\negXgPaAJkAn82Vqb6tmoRdu9ezfvv/8+L7zwAg0aNGD37t1Urly5ND5axL9c4gzb05xq+Xu+Zdrg\n4OA/NC47efKk2/uyfPnyP9xmMzIykg0bNpCbm1uwLHNGZmYm3377Lb/88gvGGHJycjDGMHr0aI9e\nHV/szN0YEwRMAjoDLuABY4zrrGHxwCFrbQNgPPCGxxKe5dhVERy7KoLc3FwmT55MZGQkI0eOLFhj\nU2EX8S+l3fK3devWfPjhh0DeTbB3795No0aNCAkJYf369eTm5pKWlsbatWsL3lOuXLkSHfANCwsj\nNjaWV155peAfk+3bt7No0SLmz5/Pww8/zK5du0hNTSUtLY369esXLDF5ijvLMk2BZGttirX2NPAx\n0P2sMd2BMz+Z+UB746UGLbcOnM7V7QfTtm1b/vrXv9KsWTM2b96sRl8iPsrXWv4OHDiQnJwcoqOj\n+fOf/8ycOXOoUKECLVq0oH79+kRHRzN48OA/LOv269ePG264odgDqoXNmDGD/fv306BBA6Kjo+nb\nty/XX389CQkJ3H333X8Ye++99/LRRx+5vW13FNvy1xhzH9DJWvtY/uPeQJy19olCY37JH5Oe/3hH\n/piDRW0TLr7lb3Z2Ng0aNODIkSOMHz+eRx55RI2+RM5DLX/926W0/HVnzb2oynn2vwjujMEY0w/o\nB1C3bl03PvpcwcHBfPDBB4SFhVGzZs2L2oaISKBzZ1kmHahT6HFtYO/5xhhjgoErgf+cvSFr7TRr\nbay1NrZ69eoXlxho2bKlCruIyAW4U9x/AhoaY+obY8oDvYDFZ41ZDDyS//19wLdWVw6JiDim2GUZ\na222MeYJ4CvyToWcZa3dbIwZASRaaxcDM4H3jTHJ5M3Ye3kztIi4z1qr41J+6FLnx26d526tXQos\nPeu5oYW+Pwn0vKQkIuJxFStWJDMzk6pVq6rA+xFrLZmZmeec918SAdV+QET+qHbt2qSnp5ORkeF0\nFCmhihUrUrt27Yt+v4q7SAArV64c9evXdzqGOCCgesuIiEgeFXcRkQCk4i4iEoCKbT/gtQ82JgPY\ndZFvrwact7VBgNI+lw3a57LhUva5nrW22KtAHSvul8IYk+hOb4VAon0uG7TPZUNp7LOWZUREApCK\nu4hIAPLX4j7N6QAO0D6XDdrnssHr++yXa+4iInJh/jpzFxGRC/Dp4m6M6WSM2WqMSTbGPF/E6xWM\nMZ/kv77GGBNS+ik9y419fsYYk2SM2WiM+cYYU8+JnJ5U3D4XGnefMcYaY/z+zAp39tkYc3/+z3qz\nMcaz92BzgBu/23WNMcuNMf/O//2+04mcnmKMmWWMOZB/p7qiXjfGmAn5fx4bjTE3FzXuollrffKL\nvPbCO4BQoDywAXCdNWYgMCX/+17AJ07nLoV9bgdUyv9+QFnY5/xxlYGVwI9ArNO5S+Hn3BD4N3B1\n/uNrnc5dCvs8DRiQ/70LSHU69yXuc2vgZuCX87x+J/B/5N3J7lZgjSc/35dn7j51Y+5SUuw+W2uX\nW2tP5D/8kbw7Y/kzd37OAP8ARgMnSzOcl7izz32BSdbaQwDW2gOlnNHT3NlnC1TJ//5Kzr3jm1+x\n1q6kiDvSFdIdeM/m+RG4yhjjsVvM+XJxrwWkFXqcnv9ckWOstdnAEaBqqaTzDnf2ubB48v7l92fF\n7rMx5iagjrX2i9IM5kXu/JzDgXBjzGpjzI/GmE6lls473NnnYcBfjDHp5N0/4snSieaYkv59LxFf\nbvnrsRtz+xG398cY8xcgFmjj1UTed8F9NsZcBowHHi2tQKXAnZ9zMHlLM23J+9/Zd8aYKGvtYS9n\n8xZ39vkBYI61dpwxphl5d3eLstbmej+eI7xav3x55u6xG3P7EXf2GWPM7cCLwF3W2lOllM1bitvn\nykAUsMIYk0re2uRiPz+o6u7v9iJrbZa1diewlbxi76/c2ed44FMAa+0PQEXyerAEKrf+vl8sXy7u\nZfHG3MXuc/4SxVTyCru/r8NCMftsrT1ira1mrQ2x1oaQd5zhLmttojNxPcKd3+2F5B08xxhTjbxl\nmpRSTelZ7uzzbqA9gDEmgrziHsi3kFoMPJx/1sytwBFr7T6Pbd3pI8rFHG2+E9hG3lH2F/OfG0He\nX27I++HPA5KBtUCo05lLYZ//CfwGrM//Wux0Zm/v81ljV+DnZ8u4+XM2wJtAErAJ6OV05lLYZxew\nmrwzadYDHZzOfIn7mwDsA7LIm6XHA/2B/oV+xpPy/zw2efr3WleoiogEIF9elhERkYuk4i4iEoBU\n3EVEApCKu4hIAFJxFxEJQCruIiIBSMVdRCQAqbiLiASg/weKZN6x2yOUrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a9cadf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = cv.predict_proba(X_test)[:,1]\n",
    "y_pred_prob2 = cv2.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "fpr2, tpr2, thresholds2 = roc_curve(y_test, y_pred_prob2)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label = 'LR with PCA')\n",
    "plt.plot(fpr2, tpr2, label = 'LR without PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.65      0.71        26\n",
      "        1.0       0.89      0.93      0.91        75\n",
      "\n",
      "avg / total       0.86      0.86      0.86       101\n",
      "\n",
      "AUC: 0.8666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with PCA\")\n",
    "y_pred = cv.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('AUC: {}'.format(roc_auc_score(y_test, y_pred_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.62      0.68        26\n",
      "        1.0       0.88      0.93      0.90        75\n",
      "\n",
      "avg / total       0.85      0.85      0.85       101\n",
      "\n",
      "AUC: 0.8646153846153847\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression without PCA\")\n",
    "y_pred2 = cv2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print('AUC: {}'.format(roc_auc_score(y_test, y_pred_prob2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kNN__n_neighbors': 14, 'PCA__n_components': 10} 0.834437086093\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('PCA', PCA()),\n",
    "                     ('kNN', KNeighborsClassifier())])\n",
    "n_components = np.arange(10, 150, 10)\n",
    "n_neighbors = np.arange(5, 15)\n",
    "parameters = {'PCA__n_components': n_components,\n",
    "              'kNN__n_neighbors': n_neighbors}\n",
    "cv_knn = GridSearchCV(pipeline, param_grid=parameters)\n",
    "cv_knn.fit(X_train, y_train)\n",
    "print(cv_knn.best_params_, cv_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7821782178217822\n",
      "AUC: 0.8125641025641025\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_knn = cv_knn.predict_proba(X_test)[:,1]\n",
    "print('Accuracy: {}\\nAUC: {}'.format(cv_knn.score(X_test, y_test), roc_auc_score(y_test, y_pred_prob_knn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
